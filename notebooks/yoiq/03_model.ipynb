{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from lib.constants import PROJECT_DIR, EXPERIMENT_NAME, MLFLOW_URI\n",
    "from lib.dataset import load_train_data, load_test_data\n",
    "\n",
    "# Make sure to have the MLFlow server on before running this code.\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI)\n",
    "experiment = mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "X_train, y_train = load_train_data()\n",
    "X_test = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['layan', 'adalah', 'tidak', 'sahabat', 'person', 'malam', 'jaga', 'gelas'],\n",
       " ['kakak',\n",
       "  'enak',\n",
       "  'sangat',\n",
       "  'layan',\n",
       "  'cepat',\n",
       "  'tanggap',\n",
       "  'dan',\n",
       "  'yang',\n",
       "  'pertama',\n",
       "  'murah',\n",
       "  'senyum'],\n",
       " ['layan', 'sangat', 'ramah', 'banyak', 'promosi']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lib.sklearn.preprocess import nlp\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "custom_map = {\n",
    "    row['asal']: row['tujuan']\n",
    "    for _, row in pd.read_csv('custom-mapper.csv').iterrows()\n",
    "}\n",
    "preprocess_pipeline = Pipeline([\n",
    "    ('tokenizer', nlp.TextTokenizer()),\n",
    "    ('formalizer', nlp.WordsFormalizer()),\n",
    "    ('custom_mapper', nlp.WordsMapper(custom_map)),\n",
    "    ('lemmatization', nlp.WordsLemmatization()),\n",
    "    ('special_char_filter', nlp.SpecialCharacterFilter()),\n",
    "    # ('stop_words_filter', nlp.StopWordsFilter()),\n",
    "    ('unknown_words_filter', nlp.UnknownWordsFilter())\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "X_train_transformed[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 157, 2: 41, 3: 46, 4: 101, 5: 557}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.17405764966740578,\n",
       " 2: 0.045454545454545456,\n",
       " 3: 0.050997782705099776,\n",
       " 4: 0.11197339246119734,\n",
       " 5: 0.6175166297117517}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.006369426751592357,\n",
       " 2: 0.024390243902439025,\n",
       " 3: 0.021739130434782608,\n",
       " 4: 0.009900990099009901,\n",
       " 5: 0.0017953321364452424}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_counts = {\n",
    "    label: count\n",
    "    for label, count in zip(*np.unique(y_train, return_counts=True))\n",
    "}\n",
    "display(y_counts)\n",
    "\n",
    "y_props = {\n",
    "    label: count / len(y_train)\n",
    "    for label, count in y_counts.items()\n",
    "}\n",
    "display(y_props)\n",
    "\n",
    "y_weight = {\n",
    "    label: 1 / count\n",
    "    for label, count in y_counts.items()\n",
    "}\n",
    "display(y_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'max_iter': 2500,\n",
    "    'penalty': 'l2',\n",
    "    'shuffle': True,\n",
    "    'random_state': 99\n",
    "}\n",
    "var_params_options = [\n",
    "    {'loss': 'hinge', 'learning_rate': 'optimal'},\n",
    "    {'loss': 'log_loss', 'learning_rate': 'optimal'},\n",
    "    {'loss': 'modified_huber', 'learning_rate': 'optimal'},\n",
    "    {'loss': 'perceptron', 'learning_rate': 'optimal'},\n",
    "    {'loss': 'hinge', 'learning_rate': 'adaptive', 'eta0': 0.01},\n",
    "    {'loss': 'log_loss', 'learning_rate': 'adaptive', 'eta0': 0.01},\n",
    "    {'loss': 'modified_huber', 'learning_rate': 'adaptive', 'eta0': 0.01},\n",
    "    {'loss': 'perceptron', 'learning_rate': 'adaptive', 'eta0': 0.01},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', SGDClassifier(**params))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'SGDClassifier'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'random_state': 99,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "var_params_options = [\n",
    "    {'n_estimators': 50, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 150, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 200, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 50, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 100, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 150, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 200, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 50, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 150, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 200, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 50, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 100, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 150, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 200, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier(**params))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'RandomForestClassifier'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.sklearn.model import RegressionClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'random_state': 99,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "var_params_options = [\n",
    "    {'n_estimators': 50, 'criterion': 'squared_error'},\n",
    "    {'n_estimators': 100, 'criterion': 'squared_error'},\n",
    "    {'n_estimators': 150, 'criterion': 'squared_error'},\n",
    "    {'n_estimators': 200, 'criterion': 'squared_error'},\n",
    "    {'n_estimators': 50, 'criterion': 'friedman_mse'},\n",
    "    {'n_estimators': 100, 'criterion': 'friedman_mse'},\n",
    "    {'n_estimators': 150, 'criterion': 'friedman_mse'},\n",
    "    {'n_estimators': 200, 'criterion': 'friedman_mse'},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('regressor', RegressionClassifier(RandomForestRegressor(**params), min=1, max=5))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'RandomForestRegressor'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'random_state': 99,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "var_params_options = [\n",
    "    {'n_estimators': 50, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 150, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 200, 'criterion': 'gini', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 50, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 100, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 150, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 200, 'criterion': 'log_loss', 'class_weight': 'balanced'},\n",
    "    {'n_estimators': 50, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 150, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 200, 'criterion': 'gini', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 50, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 100, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 150, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "    {'n_estimators': 200, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', ExtraTreesClassifier(**params))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'ExtraTreesClassifier'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 99\n",
    "}\n",
    "var_params_options = [\n",
    "    {'hidden_layer_sizes': (64,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64,), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128,), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', MLPClassifier(**params))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'MLPClassifier'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoiqsram/projects/kaggle/ml-olympiad-tfugsurabaya-2024/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/yoiqsram/projects/kaggle/ml-olympiad-tfugsurabaya-2024/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lib.sklearn.model import RegressionClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 99\n",
    "}\n",
    "var_params_options = [\n",
    "    {'hidden_layer_sizes': (64,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64,), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128,), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 32, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 16, 8), 'activation': 'logistic', 'solver': 'adam'},\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', RegressionClassifier(MLPRegressor(**params), min=1, max=5))\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'MLPRegressor'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPRegressor -> SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoiqsram/projects/kaggle/ml-olympiad-tfugsurabaya-2024/venv/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "/home/yoiqsram/projects/kaggle/ml-olympiad-tfugsurabaya-2024/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/yoiqsram/projects/kaggle/ml-olympiad-tfugsurabaya-2024/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lib.sklearn.model import RegressionExtractor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=99)\n",
    "\n",
    "control_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 99\n",
    "}\n",
    "var_params_options = [\n",
    "    {'hidden_layer_sizes': (64,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128,), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 32, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 32, 8), 'activation': 'relu', 'solver': 'adam'},\n",
    "    {'hidden_layer_sizes': (128, 64, 16, 16, 8), 'activation': 'relu', 'solver': 'adam'}\n",
    "]\n",
    "\n",
    "for var_params in var_params_options:\n",
    "    params = control_params.copy()\n",
    "    params.update(var_params)\n",
    "\n",
    "    predictor_pipeline = Pipeline([\n",
    "        ('token_to_text', nlp.TokenToTextTransformer()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "        ('regressor', RegressionExtractor(MLPRegressor(**params))),\n",
    "        ('classifier', SGDClassifier()),\n",
    "    ])\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess_pipeline),\n",
    "        ('predictor', predictor_pipeline)\n",
    "    ])\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        params['model'] = 'MLPRegressor-SGDClassifier'\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model_pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=repeated_kfold,\n",
    "            scoring='f1_macro',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        score = np.mean(scores)\n",
    "        mlflow.log_metric('f1_macro', score)\n",
    "\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model_pipeline, 'model')\n",
    "\n",
    "        last_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preferred model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 120.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chosen_run_id = '3300ff72bca545dd8b38e2deef87b694'\n",
    "model_pipeline = mlflow.sklearn.load_model(f'runs:/{chosen_run_id}/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LABEL\n",
       "0      0      5\n",
       "1      1      5\n",
       "2      2      5\n",
       "3      3      1\n",
       "4      4      1\n",
       "..   ...    ...\n",
       "495  495      3\n",
       "496  496      5\n",
       "497  497      4\n",
       "498  498      1\n",
       "499  499      5\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model_pipeline.predict(X_test)\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'LABEL': predictions})\n",
    "display(submission)\n",
    "submission.to_csv('test_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check predicted label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 84, 2: 12, 3: 18, 4: 54, 5: 332}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.168, 2: 0.024, 3: 0.036, 4: 0.108, 5: 0.664}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_counts = {\n",
    "    label: count\n",
    "    for label, count in zip(*np.unique(predictions, return_counts=True))\n",
    "}\n",
    "display(prediction_counts)\n",
    "\n",
    "prediction_props = {\n",
    "    label: count / len(predictions)\n",
    "    for label, count in prediction_counts.items()\n",
    "}\n",
    "display(prediction_props)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
